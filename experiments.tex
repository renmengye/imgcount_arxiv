\section{Experiments}

\textbf{CVPPP leaf segmentation}. One instance segmentation benchmark is the
CVPPP plant leaf dataset \cite{minervini14cvppp}, which was developed due to
the importance of instance segmentation in plant phenotyping. We ran the A1
subset of CVPPP plant leaf segmentation dataset. We trained our model on 128
labelled images, and report results on the 33 test images. We compare our
performance to \cite{romeraparedes15ris}, and other top approaches that were
published with the CVPPP conference; see the collation study
\cite{scharr16leaf} for details of these  other approaches.

\textbf{KITTI car segmentation}. Instance segmentation also provides rich
information in the context of autonomous driving. Following
\cite{zhang15insseg, zhang16insseg, uhrig16insseg}, we also evaluated the model
performance on KITTI car segmentation dataset. We trained the model with 3712
training images, and report performance on 144 test images. We also examine the
relative importance of model components via ablation studies.

\textbf{MS-COCO counting}. Additionally, we train class specific models on
MS-COCO and test counting performance on the results. We chose ``person'' and
``zebra'' because these are the two of the most common classes in VQA
questions. We report counting performance on images with at least one instance
of the class: 677 zebra images, and 21,634 ``person'' images.

\input{tabs/cvppp_table.tex}
\input{figs/cvppp_fig.tex}
\input{tabs/kitti_table.tex}
\input{figs/kitti_fig.tex}
\input{count_fig.tex}

\textbf{Evaluation metrics}. We report the  metrics used by the other studies
in the respective benchmarks: symmetric best dice (SBD) for leaf segmentation
(see Equations~\ref{eq:bd}, \ref{eq:sbd}) and mean (weighted) coverage (MWCov,
MUCov) for car segmentation (see Equations~\ref{eq:mwcov}, \ref{eq:mucov}). The
coverage scores measure the instance-wise IoU for each ground-truth instance
averaged over the image; MWCov further weights the score by the size of the
ground-truth instance segmentation (larger objects get larger weights).
%\vspace{-3pt}

\begin{align}
\label{eq:bd}
\text{DICE}(A, B) &= \frac{2 |A \cup B|}{|A| + |B|} \ \ \ \ \ \ \ \
\text{BD}(\{A_i\}, B) = \max_{i} \text{DICE}(A_i, B) \\
\label{eq:sbd}
\text{SBD}(\{\hat{y}_i\}, \{y_j\}) &= 
\min \left(\frac{1}{N} \sum_j \text{BD}(\{\hat{y}_i\}, y_j), \frac{1}{N}
\sum_i \text{BD}(\hat{y}_i, \{y_j\}) \right)
\end{align}
\vspace{-12pt}
\begin{align}
\label{eq:mwcov}
\text{MWCov}(\{y_i\}, \{y_j^*\}) &= \frac{1}{N} \sum_i 
\frac{|y_i|}{\sum_i |y_i|} \max_j
\text{IoU}(y_i, y_j^*)\\
\label{eq:mucov}
\text{MUCov}(\{y_i\}, \{y_j^*\}) &= \frac{1}{N} \sum_i 
\max_j \text{IoU}(y_i, y_j^*)
\end{align}

Counting is measured in absolute difference in count (|DiC|) (see
Equation~\ref{eq:dic}), average false positive (AvgFP), and average false
negative (AvgFN). False positive is the number of predicted instances that do
not overlap with the ground-truth, and false negative is the number of 
ground-truth instances that do not overlap with the prediction.
\vspace{-3pt}
\begin{align}
\label{eq:dic}
|DiC| = \frac{1}{N}\sum_i |count_i - count_i^*|
\end{align}
\vspace{-12pt}

\subsection{Results \& discussion}
\vspace{-3pt}
In the leaf segmentation task, our best model outperforms the previous 
state-of-the-art by a large margin in both segmentation and counting.
Table~\ref{tab:cvppp} shows that the models with FCN overfit and 
scores lower than the simpler version. This is sensible as the dataset size
is small, and including the FCN significantly increases the input dimension and
number of parameters.

In the car segmentation task, our model achieves the state-of-the-art MWCov
shown in Table~\ref{tab:kitti}, but our MUCov is lower than results reported by
Uhrig et al. \cite{uhrig16insseg}. One possible explanation is their inclusion
of depth information during training, which may help the model disambiguate
distant object boundaries. Moreover, their bottom-up ``instance fusion'' method
plays a crucial role (omitting this leads to a steep performance drop); this
likely helps segment smaller objects, whereas our box network does not reliably
detect distant cars.

In the zebra counting task, we found that our model outperforms the detector
and NMS method, and associative-subitizing methods~\cite{chattopadhyay16count},
but we are not doing as well in the person category. Figure~\ref{fig:count}
shows the relation between counting performance and number of instances. Mean
absolute difference in count is around 1 for up to 18 leaves, 7 cars, 4 zebras
and 3 people. However, relative to these regression-based methods,  our model
permits insight into the recognition of each instance by inspecting the output
segmentation.

From the figures above we see our model is handling a significant amount of
object occlusion and truncation. We verified that the external memory helps
with the counting process as the network first segments the more salient
objects and then accounts for the occluded instances. In addition, our
segmentation network can handle a range of object sizes because of the
design of the box network.

We found that using scheduled sampling results in much better performance. It
helps by making training resemble testing, gradually forcing the model
to carry out a full sequence during training instead of relying on ground-truth input. Finally, the convolutional and attentional architecture
significantly reduces the number of parameters and the performance is quite
strong despite being trained with only 100 leaf images and 1000 zebra images.

\input{figs/coco_person_fig.tex}
\input{figs/coco_zebra_fig.tex}
