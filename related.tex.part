\section{Related Work}

Instance segmentation has recently received a burst of research attention, as
it provides higher level of precision of image understanding compared to object
detection and semantic segmentation.

\textbf{Detector-based approaches}.
Early work on object segmentation \cite{borenstein02topdown} starts from a 
trained class detectors, which provide
a bottom-up merging criterion based on top-down detections.
\cite{yang12layer} extends this approach with a
DPM detector, and uses layered graphical models to reason about instance 
separation and occlusion.
Simultaneous detection and segmentation (SDS) methods 
\cite{hariharan14simultaneous,hariharan15hypercolumn,liang15rrinsseg,
li16iterative} apply newer CNN-based 
detectors such as RCNN \cite{girshick14rcnn}, and perform segmentation using the 
bounding boxes as starting point. \cite{li16iterative} proposes a trainable 
iterative refining procedure to get better object segmentation masks. SDS 
methods have been shown to effectively improve both detection and semantic 
segmentation performance. Dai et al.~\cite{dai15insaware} propose a 
pipeline-based
approach which first predicts bounding box proposals and extracts regions of 
interest (ROI), then uses shared features to perform segmentation within each 
ROI. Their architecture can also be fine-tuned end-to-end. 
Similar to those methods, we jointly learn a detector and a segmentor in our
model; however, we introduce a direct feedback loop in the sequence of 
predictions. In addition, we learn to learn the sequence ordering from a 
ranking loss.

\textbf{Graphical model approaches}. 
Another line of research is to use generative graphical model to express the
dependency structure among instances and pixels. 
Eslami et al. \cite{eslami16shapebm} proposes a restricted Boltzmann machine to
capture
high-order pixel interactions for shape modelling.
A multi-stage pipeline proposed by Silberman et al. \cite{silberman14insseg} 
is composed of patch-wise features based on deep learning, combined into a 
segmentation tree.
They formulate a new loss function, the coverage
score, that calculates the proportion of ground truth regions not covered by the
model's instance segmentations. More recently, Zhang et al. \cite{zhang16insseg}
formulate a dense CRF for instance segmentation; they apply a CNN on dense
image patches to make local predictions, and construct a dense CRF to produce
globally consistent labellings. Their key contribution is a shifting-label
potential that encourages consistency across different patches. They achieve
strong results on the challenging KITTI object dataset; however, the graphical
model formulation entails long running times, and their energy functions are
dependent on instances being connected and having a clear depth ordering.

\textbf{Fully convolutional approaches}. 
Fully convolutional networks \cite{long15fcn} has emerged as a powerful tool to
directly predict dense pixel labellings.
Pinheiro et al.~\cite{pinheiro15seg,pinheiro16refine}
train a CNN to generate object segmentation proposals, which runs densely on
all windows at multiple scales, and Dai et al.~\cite{dai16insfcn} uses relative 
location as additional pixel labels. The output of both systems are object
proposals, which require further processing to get final instance-level
segmentations. 
Other approaches using FCNs are proposal-free, but rely on a bottom-up merging
process. 
Liang et al.~\cite{liang15pfinsseg} predict dense pixel prediction of object 
location and size, using clustering as a post-processing step. 
Uhrig et al.~\cite{uhrig16insseg} present another approach based on FCNs, in which 
it is trained to produces a semantic segmentation as well as an instance-aware angle 
map, encoding the centroid of each instance. Post-processing based on template 
matching and instance fusion produce the instance identities. Importantly,
they also used ground-truth depth labels in training their model.

\textbf{RNN approaches}. Another recent line of research, e.g.,
\cite{stewart15lstmdet, park15ris, romeraparedes15ris} employs end-to-end
recurrent neural networks (RNN) to perform object detection and segmentation. A
permutation agnostic loss function based on maximum weighted bipartite matching
was proposed by \cite{stewart15lstmdet}. To process an entire image, they treat
each element of a $15\times20$ feature map individually. Similarly, our box
proposal network also uses an RNN to generate box proposals: instead of running
the image 300 times through the RNN, we only run it once by using a soft
attention mechanism \cite{xu15caption}. Romera-Paredes and Torr
\cite{romeraparedes15ris} use convolutional LSTM (ConvLSTM)
\cite{shi2015convlstm} to produce instance segmentation directly. However,
since their ConvLSTM is required to handle object detection, inhibition, and
segmentation all convolutionally on a global scale, the final output loses
precision, and it is hard for their model to inhibit far apart instances. 
In contrast to their
approach, our architecture incorporates direct feedback from the prediction
of the previous instance, providing precise boundary inhibition, and our 
box network confines the instance-wise pixel segmentation within a local 
window.


%% Difference!!!

% \textbf{Instance counting}. Previous work on object counting in images has
% mainly focused on crowds of pedestrians and biological cells
% \cite{lempitsky10count}. Chattopadhyay et al. \cite{chattopadhyay16count}
% focused on counting questions in VQA and proposed detector approaches as well
% as a regression based method (``associative subitizing'') that works on a $3
% \times 3$ field of CNN features level. Note that unlike our approach, this
% method does not provide instance segmentations.
